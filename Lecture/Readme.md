[Google Drive for Lecture Videos](https://drive.google.com/drive/folders/1IEawjPjOiU6AqRGhyIbAWLIBJN1EuLXe)

We will be posting lecture materials and associated reading here.

* __Readings for Week 1:__
  * Geometry/Topology: [Hypersphere](https://en.wikipedia.org/wiki/N-sphere), [Hypercube](https://en.wikipedia.org/wiki/Hypercube), [Hyperplane](https://en.wikipedia.org/wiki/Hyperplane)
  
  * Statistics: [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem),[Covariance](https://en.wikipedia.org/wiki/Covariance_matrix),[Multivariate Normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)

  * Data/Feature Scaling: [Wiki](https://en.wikipedia.org/wiki/Feature_scaling), [DS](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)
  
  Videos: [Normal](https://www.youtube.com/watch?v=eho8xH3E6mE), [Covariance](https://www.youtube.com/watch?v=152tSYtiQbw) 
  
* __Readings for Week 2__

  * Key Words: [Vector Projections](https://en.wikipedia.org/wiki/Vector_projection),[Projection Matrix](https://en.wikipedia.org/wiki/Projection_matrix), [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis), [Singular Value Decomposition (SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition), [Gram Schmidt](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process), [Linear Regression](https://en.wikipedia.org/wiki/Linear_regression), [John Lindenstrauss (JL) Lemma](https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma)

Interesting Blog: http://colah.github.io/posts/2014-10-Visualizing-MNIST/
Face Decomposition Example: https://scikit-learn.org/0.16/auto_examples/decomposition/plot_faces_decomposition.html

  * Videos for this week: 
    * [Curse of Dimensionality and Jl Lemma:](https://www.youtube.com/watch?v=xVh6B7zhh88)
    *  Scalable Data Science Course Videos (Very similar NPTEL course)[link](https://www.youtube.com/watch?v=pdg2MUZLeSE&list=PLbRMhDVUMngekIHyLt8b_3jQR7C0KUCul)

* __Readings for Week 3__
  * [LSH](http://www.mit.edu/~andoni/LSH/),[LSH Application](https://santhoshhari.github.io/Locality-Sensitive-Hashing/),[LSH Uber](https://eng.uber.com/lsh/)
  * [LSH Example Code](http://ethen8181.github.io/machine-learning/recsys/content_based/lsh_text.html)
  * Optional [Compressed Sensing](https://cnx.org/contents/9wtroLnw@5.12:lh465hW1@7/Introduction-to-compressive-sensing)
  * Optional [Kernel Methods]
  * Image retreival : Read the Kaggle challenge problem: https://www.kaggle.com/c/landmark-retrieval-2019

  * Videos for the week 
   * [LSH](https://www.youtube.com/watch?v=YVL7QlRWd24)
   * [Compressed Sensing](http://databookuw.com/page-2/page-13/)(https://www.youtube.com/watch?v=W-b4aDGsbJk)
   * [Kernel Methods]()
 

* __Readings for Week 4___
  * https://datasketches.apache.org/docs/Background/TheChallenge.html
  * https://nptel.ac.in/courses/106/105/106105186/
  * SSBD book Chapters 3 and 4



* __Readings for Machine Learning___
  * Nearest Neighbor Approach to Computer Vision: https://cs231n.github.io/classification/
  * Object Detection Short Course: https://people.csail.mit.edu/torralba/shortCourseRLOC/index.html
  * Linear Classification (Great Tutorial with interactive demo): https://cs231n.github.io/linear-classify/#softmax-classifier
  * Decision Trees, Pruning: https://www.cs.cmu.edu/~bhiksha/courses/10-601/decisiontrees/
  * Very simple explanation for Neural Networks: http://neuralnetworksanddeeplearning.com/index.html
  * ML as Optimization: http://helper.ipam.ucla.edu/publications/elws1/elws1_13686.pdf 
  * Colah' blog : https://colah.github.io/
  * https://www.kdnuggets.com/2019/09/friendly-introduction-support-vector-machines.html
  * https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html
  * https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html
  * https://towardsai.net/p/programming/decision-trees-explained-with-a-practical-example-fe47872d3b53
  * 

* __Back Propagation Explained__
   * Developing Intuition for Solving Optimization Problems: https://cs231n.github.io/optimization-1/
   * Intuition for Backpropgation: https://cs231n.github.io/optimization-2/
   * Momentum Methods for Finding Optimal Solutions: https://distill.pub/2017/momentum/
 
 * __Conv Neural Nets__
   * Gentle Intro: https://cs231n.github.io/convolutional-networks/
 




   * 

